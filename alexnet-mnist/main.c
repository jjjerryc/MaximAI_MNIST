/*******************************************************************************
* Copyright (C) 2019-2024 Maxim Integrated Products, Inc., All rights Reserved.
*
* This software is protected by copyright laws of the United States and
* of foreign countries. This material may also be protected by patent laws
* and technology transfer regulations of the United States and of foreign
* countries. This software is furnished under a license agreement and/or a
* nondisclosure agreement and may only be used or reproduced in accordance
* with the terms of those agreements. Dissemination of this information to
* any party or parties not specified in the license agreement and/or
* nondisclosure agreement is expressly prohibited.
*
* The above copyright notice and this permission notice shall be included
* in all copies or substantial portions of the Software.
*
* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
* OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
* MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
* IN NO EVENT SHALL MAXIM INTEGRATED BE LIABLE FOR ANY CLAIM, DAMAGES
* OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
* ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
* OTHER DEALINGS IN THE SOFTWARE.
*
* Except as contained in this notice, the name of Maxim Integrated
* Products, Inc. shall not be used except as stated in the Maxim Integrated
* Products, Inc. Branding Policy.
*
* The mere transfer of this software does not imply any licenses
* of trade secrets, proprietary technology, copyrights, patents,
* trademarks, maskwork rights, or any other form of intellectual
* property whatsoever. Maxim Integrated Products, Inc. retains all
* ownership rights.
*******************************************************************************/

// alexnet-mnist
// This file was @generated by /home/jayson_c/Maxim/ai8x-synthesis/ai8xize.py --test-dir sdk/MAX78002/CNN --prefix alexnet-mnist --checkpoint-file /home/jayson_c/Maxim/ai8x-training/mnist_Project/alexnet-mnist-qat8-q.pth.tar --config-file /home/jayson_c/Maxim/ai8x-training/mnist_Project/alexnet-mnist.yaml --softmax --device MAX78002 --timer 0 --display-checkpoint --verbose --overwrite

#include <assert.h>
#include <stdlib.h>
#include <stdint.h>
#include <string.h>
#include <stdio.h>
#include "mxc.h"
#include "cnn.h"
#include "test_data.h"

volatile uint32_t cnn_time; // Stopwatch

void fail(void)
{
  printf("\n*** FAIL ***\n\n");
  while (1);
}

// 1-channel 28x28 data input (784 bytes / 196 32-bit words):
// CHW 28x28, channel 0
void load_input(int index)
{
    // 使用正確的陣列形式取得資料
    const uint32_t *current_image = test_images[index];
    
    // 複製數據到 CNN 輸入緩衝區
    memcpy32((uint32_t *) 0x51800000, current_image, 196);
}

// Classification layer:
static int32_t ml_data[CNN_NUM_OUTPUTS];
static q15_t ml_softmax[CNN_NUM_OUTPUTS];

void softmax_layer(void)
{
    cnn_unload((uint32_t *) ml_data);
    // 執行 softmax
    softmax_q17p14_q15((const q31_t *) ml_data, CNN_NUM_OUTPUTS, ml_softmax);
}

int get_prediction(void)
{
    int prediction = 0;
    // 使用 softmax 後的值來做預測
    q15_t max_value = ml_softmax[0];
    
    for (int i = 1; i < CNN_NUM_OUTPUTS; i++) {
        if (ml_softmax[i] > max_value) {
            max_value = ml_softmax[i];
            prediction = i;
        }
    }
    return prediction;
}

void print_confusion_matrix(int matrix[CNN_NUM_OUTPUTS][CNN_NUM_OUTPUTS], int num_classes)
{
    printf("\nConfusion Matrix:\n");
    printf("     ");
    for (int i = 0; i < num_classes; i++) {
        printf("%4d ", i);
    }
    printf("\n");

    for (int i = 0; i < num_classes; i++) {
        printf("%4d ", i);
        for (int j = 0; j < num_classes; j++) {
            printf("%4d ", matrix[i][j]);
        }
        printf("\n");
    }
}


int main(void)
{
    int correct_predictions = 0;
    int total_predictions = 0;
    int confusion_matrix[CNN_NUM_OUTPUTS][CNN_NUM_OUTPUTS] = {0};

    MXC_ICC_Enable(MXC_ICC0); // Enable cache

    // Switch to 120 MHz clock
    MXC_SYS_Clock_Select(MXC_SYS_CLOCK_IPO);
    MXC_GCR->ipll_ctrl |= MXC_F_GCR_IPLL_CTRL_EN;
    SystemCoreClockUpdate();

    printf("\n*** CNN Model Evaluation ***\n");
    
    // 初始化 CNN
    cnn_enable(MXC_S_GCR_PCLKDIV_CNNCLKSEL_IPLL, MXC_S_GCR_PCLKDIV_CNNCLKDIV_DIV4);
    cnn_init();
    cnn_load_weights();
    cnn_load_bias();
    cnn_configure();

    // 評估所有測試數據
    for (int test_idx = 0; test_idx < 3000; test_idx++) {
        // 載入當前測試圖像
        load_input(test_idx);
        
        // 設置 CNN 時鐘並開始處理
        MXC_GCR->pclkdiv = (MXC_GCR->pclkdiv & ~(MXC_F_GCR_PCLKDIV_CNNCLKDIV | MXC_F_GCR_PCLKDIV_CNNCLKSEL))
                         | MXC_S_GCR_PCLKDIV_CNNCLKDIV_DIV1 | MXC_S_GCR_PCLKDIV_CNNCLKSEL_IPLL;
        
        cnn_start();
        while (cnn_time == 0) {
            MXC_LP_EnterSleepMode();
        }

        // 切換回較慢的時鐘
        MXC_GCR->pclkdiv = (MXC_GCR->pclkdiv & ~(MXC_F_GCR_PCLKDIV_CNNCLKDIV | MXC_F_GCR_PCLKDIV_CNNCLKSEL))
                         | MXC_S_GCR_PCLKDIV_CNNCLKDIV_DIV4 | MXC_S_GCR_PCLKDIV_CNNCLKSEL_IPLL;

        softmax_layer();
        int prediction = get_prediction();

        confusion_matrix[test_labels[test_idx]][prediction]++;
        
        if (prediction == test_labels[test_idx]) {
            correct_predictions++;
        }
        total_predictions++;

        if ((test_idx + 1) % 100 == 0) {
            printf("Processed %d/1000 images, Current Accuracy: %.2f%%\n", 
                   test_idx + 1, 
                   (double)correct_predictions * 100.0 / total_predictions);
        }
    }

    printf("\nTest Complete!\n");
    printf("Total Images: %d\n", total_predictions);
    printf("Correct Predictions: %d\n", correct_predictions);
    printf("Final Accuracy: %.2f%%\n", 
           (double)correct_predictions * 100.0 / total_predictions);

    print_confusion_matrix(confusion_matrix, CNN_NUM_OUTPUTS);

    cnn_disable();
    MXC_GCR->ipll_ctrl &= ~MXC_F_GCR_IPLL_CTRL_EN;

    return 0;
}

/*
  SUMMARY OF OPS
  Hardware: 11,263,184 ops (11,129,376 macc; 129,328 comp; 4,480 add; 0 mul; 0 bitwise)
    Layer 0: 470,400 ops (423,360 macc; 47,040 comp; 0 add; 0 mul; 0 bitwise)
    Layer 1: 8,356,800 ops (8,294,400 macc; 62,400 comp; 0 add; 0 mul; 0 bitwise)
    Layer 2: 1,954,304 ops (1,935,360 macc; 18,944 comp; 0 add; 0 mul; 0 bitwise)
    Layer 3: 456,064 ops (451,584 macc; 896 comp; 3,584 add; 0 mul; 0 bitwise)
    Layer 4: 25,136 ops (24,192 macc; 48 comp; 896 add; 0 mul; 0 bitwise)
    Layer 5: 480 ops (480 macc; 0 comp; 0 add; 0 mul; 0 bitwise)

  RESOURCE USAGE
  Weight memory: 97,932 bytes out of 2,396,160 bytes total (4.1%)
  Bias memory:   10 bytes out of 8,192 bytes total (0.1%)
*/

